{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"Set2\")\n",
    "\n",
    "# 한글 설정\n",
    "plt.rc(\"font\", family=\"AppleGothic\")\n",
    "plt.rcParams['axes.unicode_minus'] = False   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pd.read_csv(\"data/processed/train_label.csv\")\n",
    "test_label = pd.read_csv(\"data/processed/test_label.csv\")\n",
    "\n",
    "activity = pd.read_csv(\"./data/processed/activity.csv\", parse_dates=['activity_date'])\n",
    "met_class = pd.read_csv(\"./data/processed/log/met_class.csv\", parse_dates=['activity_date'])\n",
    "met_log = pd.read_csv(\"./data/processed/log/met_log.csv\", parse_dates=['activity_date'])\n",
    "\n",
    "sleep = pd.read_csv(\"./data/processed/sleep.csv\", parse_dates=['sleep_bedtime_start','sleep_bedtime_end'])\n",
    "sleep_log = pd.read_csv(\"./data/processed/log/sleep_log.csv\", parse_dates=['sleep_bedtime_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set\n",
    "train_activity = activity.merge(train_label, how=\"inner\", on=\"EMAIL\")\n",
    "train_metclass = met_class.merge(train_label, how=\"inner\", on=\"EMAIL\")\n",
    "train_metlog = met_log.merge(train_label, how=\"inner\", on=\"EMAIL\")\n",
    "train_sleep = sleep.merge(train_label, how=\"inner\", on=\"EMAIL\")\n",
    "\n",
    "# test set\n",
    "test_activity = activity.merge(test_label, how=\"inner\", on=\"EMAIL\")\n",
    "test_metclass = met_class.merge(test_label, how=\"inner\", on=\"EMAIL\")\n",
    "test_metlog = met_log.merge(test_label, how=\"inner\", on=\"EMAIL\")\n",
    "test_sleep = sleep.merge(test_label, how='inner', on=[\"EMAIL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Activity:  (9705, 27)\n",
      "Train MET Class:  (2780866, 5)\n",
      "Train MET Log:  (13975200, 5)\n",
      "============================================================\n",
      "Test Activity:  (2478, 27)\n",
      "Test MET Class:  (711217, 5)\n",
      "Test MET Log:  (3568320, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Activity: \", train_activity.shape)\n",
    "print(\"Train MET Class: \", train_metclass.shape)\n",
    "print(\"Train MET Log: \", train_metlog.shape)\n",
    "print(\"=\"*60)\n",
    "print(\"Test Activity: \", test_activity.shape)\n",
    "print(\"Test MET Class: \", test_metclass.shape)\n",
    "print(\"Test MET Log: \", test_metlog.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activity 이상치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def is_outlier(row):\n",
    "    \"\"\"이상치를 판별하는 함수\"\"\"\n",
    "    return (\n",
    "        10000 <= row['activity_steps'] <= 20000 and\n",
    "        row['activity_total'] <= 2000 and\n",
    "        row['activity_cal_active'] <= 100 and\n",
    "        row['activity_daily_movement'] <= 1000\n",
    "    )\n",
    "\n",
    "def calculate_median(train_data, col):\n",
    "    \"\"\"이상치가 아닌 데이터의 중앙값을 계산\"\"\"\n",
    "    return train_data.loc[~train_data['is_outlier'], col].median()\n",
    "\n",
    "def get_low_steps_group(train_data):\n",
    "    \"\"\"낮은 activity_steps 그룹을 추출\"\"\"\n",
    "    return train_data[(450 < train_data['activity_steps']) & (train_data['activity_steps'] <= 700)]\n",
    "\n",
    "def remove_outliers(data, reference_data=None):\n",
    "    \"\"\"\n",
    "    이상치를 탐지하고 적절한 값으로 대체하는 함수\n",
    "    - data: 이상치를 처리할 데이터셋 (train/test)\n",
    "    - reference_data: 중앙값 및 대체값을 계산할 기준 데이터셋 (train 사용 권장)\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    \n",
    "    # 이상치 탐지\n",
    "    df['is_outlier'] = df.apply(is_outlier, axis=1)\n",
    "\n",
    "    # 중앙값 및 평균값 계산을 위한 기준 데이터 선택\n",
    "    ref = reference_data if reference_data is not None else df\n",
    "    low_steps = get_low_steps_group(ref)\n",
    "    \n",
    "    # 이상치 대체값 계산 (낮은 steps 그룹의 평균)\n",
    "    replace_value = int(low_steps['activity_steps'].mean()) if not low_steps.empty else df['activity_steps'].median()\n",
    "\n",
    "    # 이상치 처리\n",
    "    df.loc[df['is_outlier'], 'activity_steps'] = replace_value\n",
    "    df.drop(columns=['is_outlier'], inplace=True)  # 이상치 여부 컬럼 제거\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## activity met log 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def remove_high_zero_ratio_entries(df, threshold=0.8):\n",
    "    \"\"\" EMAIL, activity_date별 MET 0 비율이 일정 비율(threshold) 이상이면 제거 \"\"\"\n",
    "    zero_ratio = df.groupby([\"EMAIL\", \"activity_date\"])[\"met\"].apply(lambda x: (x == 0).mean())\n",
    "    remove_idx = zero_ratio[zero_ratio >= threshold].index\n",
    "    df = df[~df.set_index([\"EMAIL\", \"activity_date\"]).index.isin(remove_idx)]\n",
    "    return df, remove_idx\n",
    "\n",
    "def correct_met_values(df, remove=True):\n",
    "    \"\"\"\n",
    "    MET < 1 값 보정 처리 함수\n",
    "    - 0이 80% 이상이면 해당 그룹 삭제\n",
    "    - 0.9 → 1로 변경\n",
    "    - 0.9 미만 → 선형 보간\n",
    "    - 보간 후 남은 결측값 → 1로 변경\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"met_interpolated\"] = df[\"met\"]  # 보정용 컬럼 추가\n",
    "    \n",
    "    # MET 0 비율이 80% 이상인 데이터 삭제\n",
    "    if remove:\n",
    "        df, removed_entries = remove_high_zero_ratio_entries(df)\n",
    "        print(\"제거된 데이터 그룹:\", removed_entries)\n",
    "\n",
    "    # 0.9 → 1 변환\n",
    "    df[\"met_interpolated\"] = df[\"met_interpolated\"].replace(0.9, 1)\n",
    "\n",
    "    # MET < 0.9 값 → NaN 처리 후 선형 보간\n",
    "    df.loc[df['met_interpolated'] < 0.9, 'met_interpolated'] = np.nan\n",
    "    df = df.groupby([\"EMAIL\", \"activity_date\"]).apply(\n",
    "        lambda x: x.interpolate(method=\"linear\", limit_direction=\"both\", limit_area=\"inside\", axis=0)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # 보간 후 남은 NaN 값 → 1로 대체\n",
    "    df.loc[df['met_interpolated'].isna(), 'met_interpolated'] = 1.0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chronotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_period(minutes):\n",
    "    \"\"\" 분 단위 시간을 morning/daytime/evening/night로 매핑 \"\"\"\n",
    "    if 0 <= minutes <= 359:\n",
    "        return \"morning\"\n",
    "    elif 360 <= minutes <= 719:\n",
    "        return \"daytime\"\n",
    "    elif 720 <= minutes <= 1079:\n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return \"night\"\n",
    "\n",
    "# import pandas as pd\n",
    "# from time_utils import get_time_period\n",
    "\n",
    "def compute_activity_pattern(df):\n",
    "    \"\"\"\n",
    "    사람별 시간대별 평균 MET 및 최대 활동 시간대 계산\n",
    "    - df: MET 로그 데이터 (train_metlog 등)\n",
    "    - 반환값: activity_pattern (사람별 시간대별 평균 MET, max_activity_time 포함)\n",
    "    \"\"\"\n",
    "    df[\"time_period\"] = df[\"minutes_time\"].apply(get_time_period)\n",
    "    \n",
    "    # 시간대별 평균 MET 계산\n",
    "    activity_pattern = df.groupby([\"EMAIL\", \"time_period\"])[\"met_interpolated\"].mean().unstack()\n",
    "    \n",
    "    # 각 사람별 최대 활동 시간대\n",
    "    activity_pattern[\"max_activity_time\"] = activity_pattern.idxmax(axis=1)\n",
    "\n",
    "    return activity_pattern\n",
    "\n",
    "def classify_activity_type(activity_pattern):\n",
    "    \"\"\"\n",
    "    특정 시간대 비율이 일정 기준 이상이면 그 유형으로 분류\n",
    "    - activity_pattern: compute_activity_pattern의 결과 데이터\n",
    "    - 반환값: activity_pattern (activity_type 추가됨)\n",
    "    \"\"\"\n",
    "    activity_pattern = activity_pattern.copy()\n",
    "    \n",
    "    # 날짜별 시간대 평균 MET 계산\n",
    "    activity_pattern = activity_pattern.groupby([\"EMAIL\", \"activity_date\", \"time_period\"])[\"met_interpolated\"].mean().unstack()\n",
    "    \n",
    "    # 특정 시간대 비율 계산\n",
    "    activity_pattern[\"total_met\"] = activity_pattern.sum(axis=1)\n",
    "    activity_pattern[\"morning_ratio\"] = (activity_pattern[\"morning\"] + activity_pattern[\"daytime\"]) / activity_pattern[\"total_met\"]\n",
    "    activity_pattern[\"evening_ratio\"] = (activity_pattern[\"evening\"] + activity_pattern[\"night\"]) / activity_pattern[\"total_met\"]\n",
    "\n",
    "    # 활동 유형 분류\n",
    "    activity_pattern[\"activity_type\"] = \"intermediate\"\n",
    "    activity_pattern.loc[activity_pattern[\"morning_ratio\"] > 0.55, \"activity_type\"] = \"morning\"\n",
    "    activity_pattern.loc[activity_pattern[\"evening_ratio\"] > 0.55, \"activity_type\"] = \"evening\"\n",
    "\n",
    "    return activity_pattern.reset_index()\n",
    "\n",
    "def merge_activity_patterns(train_activity, activity_pattern, train_label):\n",
    "    \"\"\"\n",
    "    활동 패턴을 train_activity 및 train_label 데이터와 병합\n",
    "    - train_activity: 원본 활동 데이터\n",
    "    - activity_pattern: classify_activity_type의 결과\n",
    "    - train_label: 라벨 데이터\n",
    "    - 반환값: 병합된 train_activity, train_label 데이터\n",
    "    \"\"\"\n",
    "    train_activity = train_activity.merge(activity_pattern, how='inner', on=['EMAIL', 'activity_date'])\n",
    "    \n",
    "    # 사람별 대표적인 활동 유형 (가장 많은 유형 기준)\n",
    "    pattern_gr = activity_pattern.groupby(['EMAIL', 'activity_type'])['EMAIL'].count().unstack().idxmax(axis=1).reset_index(name='chrono_3type')\n",
    "    \n",
    "    train_label = train_label.merge(pattern_gr, how='inner', on='EMAIL')\n",
    "\n",
    "    return train_activity, train_label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chronotype 계산 through Sleep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def classify_chronotype(wake_time):\n",
    "    \"\"\"\n",
    "    기상 시간을 기준으로 chronotype을 분류합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        wake_time (datetime.time): 기상 시간 (시간, 분 정보 포함)\n",
    "\n",
    "    Returns:\n",
    "        str: 'morning', 'intermediate', 'evening' 중 하나\n",
    "    \"\"\"\n",
    "    if wake_time.hour < 6:  # 06:00 이전\n",
    "        return \"morning\"\n",
    "    elif 6 <= wake_time.hour < 9:  # 06:00~08:59\n",
    "        return \"intermediate\"\n",
    "    else:  # 09:00 이후\n",
    "        return \"evening\"\n",
    "\n",
    "def calculate_wakeup_time(row):\n",
    "    \"\"\"\n",
    "    개인의 chronotype과 실제 기상 시간의 차이를 계산하여 기상시간 점수를 생성합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        row (pd.Series): sleep 데이터의 한 행 (chronotype, sleep_bedtime_end 포함)\n",
    "    \n",
    "    Returns:\n",
    "        int: 기상 시간 점수 (이상적인 기상 시간과의 차이)\n",
    "    \"\"\"\n",
    "    ideal_wake_times = {\n",
    "        \"morning\": 6 * 60,  # 06:00 (360분)\n",
    "        \"intermediate\": 7 * 60,  # 07:00 (420분)\n",
    "        \"evening\": 9 * 60  # 09:00 (540분)\n",
    "    }\n",
    "    \n",
    "    actual_wake_time = row[\"sleep_bedtime_end\"].hour * 60 + row[\"sleep_bedtime_end\"].minute\n",
    "    ideal_wake_time = ideal_wake_times[row[\"chronotype\"]]\n",
    "    \n",
    "    return abs(actual_wake_time - ideal_wake_time)\n",
    "\n",
    "def assign_chronotype(df):\n",
    "    \"\"\"\n",
    "    주어진 데이터프레임에서 각 사용자의 chronotype을 할당하고 wakeup 점수를 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): sleep 데이터 (sleep_bedtime_end 포함)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: chronotype과 wakeup_time_score가 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"chronotype\"] = df[\"sleep_bedtime_end\"].apply(classify_chronotype)\n",
    "    df[\"wakeup_time_score\"] = df.apply(calculate_wakeup_time, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개인별 수면적정시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# Chronotype별 적정 수면 시간 (초 단위)\n",
    "CHRONOTYPE_SLEEP_GOAL = {\n",
    "    \"morning\": 7 * 60 * 60,  # 7시간\n",
    "    \"intermediate\": 7.5 * 60 * 60,  # 7시간 30분\n",
    "    \"evening\": 8 * 60 * 60  # 8시간\n",
    "}\n",
    "\n",
    "def calculate_sleep_alignment(df):\n",
    "    \"\"\"\n",
    "    Chronotype별 적정 수면 시간과 실제 수면 시간의 차이를 계산합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): sleep 데이터 (chronotype, sleep_total 포함)\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: sleep_alignment (초 단위) 컬럼\n",
    "    \"\"\"\n",
    "    return df[\"sleep_total\"] - df[\"chronotype\"].map(CHRONOTYPE_SLEEP_GOAL)\n",
    "\n",
    "def calculate_abnormal_wake_time(df):\n",
    "    \"\"\"\n",
    "    비정상 기상 여부를 판별합니다 (평균 기상시간과 1.5표준편차 이상 차이).\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): sleep 데이터 (평균 기상시간, 표준편차 포함)\n",
    "    \n",
    "    Returns:\n",
    "        pd.Series: abnormal_wake_time (0 또는 1)\n",
    "    \"\"\"\n",
    "    threshold = 1.5 * df[\"std_wake_time\"]\n",
    "    return np.where(np.abs(df[\"sleep_bedtime_end\"].dt.hour - df[\"avg_wake_time\"]) > threshold, 1, 0)\n",
    "\n",
    "def process_sleep_data(df):\n",
    "    \"\"\"\n",
    "    수면 데이터 전처리 및 분석을 수행합니다.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): sleep 데이터 (sleep_total, sleep_duration 포함)\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: 분석된 sleep 데이터\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 수면 정렬도 (Sleep Alignment) 계산\n",
    "    df[\"sleep_alignment_chronotype\"] = calculate_sleep_alignment(df)\n",
    "    df[\"sleep_alignment_chronotype_mins\"] = df[\"sleep_alignment_chronotype\"] / 60  # 초 -> 분 변환\n",
    "\n",
    "    # 수면 시간 변환 (초 → 시간)\n",
    "    df[\"sleep_duration_hours\"] = df[\"sleep_duration\"] / 60 / 60\n",
    "\n",
    "    # 기상시간 및 취침시간 변환\n",
    "    df[\"wake_time\"] = df[\"sleep_bedtime_end\"].dt.time\n",
    "    df[\"bed_time\"] = df[\"sleep_bedtime_start\"].dt.time\n",
    "\n",
    "    # 사람별 평균 수면 패턴 계산\n",
    "    person_avg = df.groupby(\"EMAIL\").agg(\n",
    "        avg_wake_time=(\"sleep_bedtime_end\", lambda x: x.dt.hour.mean()),  # 평균 기상시간\n",
    "        avg_sleep_duration=(\"sleep_duration_hours\", \"mean\"),  # 평균 수면시간\n",
    "        std_wake_time=(\"sleep_bedtime_end\", lambda x: x.dt.hour.std()),  # 기상시간 표준편차\n",
    "        std_sleep_duration=(\"sleep_duration_hours\", \"std\")  # 수면시간 표준편차\n",
    "    ).reset_index()\n",
    "\n",
    "    # 원본 데이터와 병합\n",
    "    df = df.merge(person_avg, on=\"EMAIL\", how=\"left\")\n",
    "\n",
    "    # Sleep Alignment 계산\n",
    "    df[\"sleep_alignment\"] = np.abs(df[\"sleep_duration_hours\"] - df[\"avg_sleep_duration\"])\n",
    "\n",
    "    # 비정상 기상 여부 계산\n",
    "    df[\"abnormal_wake_time\"] = calculate_abnormal_wake_time(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na_with_user_median(df, column_name):\n",
    "    \"\"\"\n",
    "    shift, moving average 계산으로 비어있는 앞의 값 평균으로 채우기 개별 사용자의 중앙값으로 채운다.\n",
    "    \"\"\"\n",
    "    # 사용자별 평균 계산\n",
    "    user_medians = df.groupby(\"EMAIL\")[column_name].transform(\"median\")\n",
    "\n",
    "    # NaN 값을 해당 사용자의 중앙값으로 채움\n",
    "    df[column_name].fillna(user_medians, inplace=True)\n",
    "    return df\n",
    "\n",
    "def generate_time_lag_features(df, column, lags=[2, 3], rolling_windows=[3, 7, 30]):\n",
    "    \"\"\"\n",
    "    특정 컬럼(column)에 대해 Time Lag 변수와 이동 평균 변수를 생성하는 함수.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "    - column: 타겟 컬럼명 (예: 'deep_ratio_5h' 또는 'awake_ratio_5h')\n",
    "    - lags: Time Lag을 만들 간격 리스트 (기본값: [2, 3])\n",
    "    - rolling_windows: 이동 평균을 계산할 윈도우 크기 리스트 (기본값: [3, 7, 30])\n",
    "\n",
    "    Returns:\n",
    "    - 변형된 DataFrame (원본 df에 새로운 컬럼 추가)\n",
    "    \"\"\"\n",
    "    for lag in lags:\n",
    "        df[f\"{column}_lag{lag}\"] = df.groupby(\"EMAIL\")[column].shift(lag)\n",
    "        df = fill_na_with_user_median(df, f\"{column}_lag{lag}\")\n",
    "\n",
    "    for window in rolling_windows:\n",
    "        df[f\"{column}_{window}d_avg\"] = df.groupby(\"EMAIL\")[column].transform(\n",
    "            lambda x: x.rolling(window, min_periods=1).mean()\n",
    "        )\n",
    "        df = fill_na_with_user_median(df, f\"{column}_{window}d_avg\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제거된 데이터 그룹: MultiIndex([('nia+411@rowan.kr', '2020-12-05')],\n",
      "           names=['EMAIL', 'activity_date'])\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "clean_train = remove_outliers(train_activity)\n",
    "clean_train_metlog = correct_met_values(train_metlog)\n",
    "\n",
    "activity_personal_type = compute_activity_pattern(clean_train_metlog)\n",
    "activity_pattern = classify_activity_type(clean_train_metlog)\n",
    "train_activity, train_label = merge_activity_patterns(clean_train, activity_pattern, train_label)\n",
    "\n",
    "train_sleep = assign_chronotype(train_sleep)\n",
    "train_sleep = process_sleep_data(train_sleep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set\n",
    "# clean_test = remove_outliers(test_activity)\n",
    "clean_test_metlog = correct_met_values(test_metlog, remove=False)\n",
    "\n",
    "activity_personal_type = compute_activity_pattern(clean_test_metlog)\n",
    "activity_pattern = classify_activity_type(clean_test_metlog)\n",
    "test_activity, test_label = merge_activity_patterns(test_activity, activity_pattern, test_label)\n",
    "\n",
    "test_sleep = assign_chronotype(test_sleep)\n",
    "test_sleep = process_sleep_data(test_sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Activity:  (9704, 35)\n",
      "Train Sleep:  (9705, 44)\n",
      "==============================\n",
      "Test Activity:  (2478, 35)\n",
      "Test Sleep:  (2478, 44)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Activity: \", train_activity.shape)\n",
    "print(\"Train Sleep: \", train_sleep.shape)\n",
    "print(\"=\"*30)\n",
    "print(\"Test Activity: \", test_activity.shape)\n",
    "print(\"Test Sleep: \", test_sleep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활동량 관련 컬럼의 이동평균 추가\n",
    "rag_cols = ['activity_average_met', 'activity_inactive', 'total_met', 'morning_ratio', 'evening_ratio']\n",
    "\n",
    "for col_name in rag_cols:\n",
    "    train_activity = generate_time_lag_features(train_activity, col_name, lags=[2, 3], rolling_windows=[3, 7, 30])\n",
    "    test_activity = generate_time_lag_features(test_activity, col_name, lags=[2, 3], rolling_windows=[3, 7, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_folder=\"data/processed\"\n",
    "# train_label_merged.to_csv(log_folder+\"/train_label_merged.csv\", index=False)\n",
    "train_activity.to_csv(log_folder+\"/train_activity_add.csv\", index=False)\n",
    "train_sleep.to_csv(log_folder+\"/train_sleep_add.csv\", index=False)\n",
    "test_activity.to_csv(log_folder+\"/test_activity_add.csv\", index=False)\n",
    "test_sleep.to_csv(log_folder+\"/test_sleep_add.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_activity = pd.read_csv(\"data/processed/train_activity_add.csv\", parse_dates=['activity_date'])\n",
    "train_sleep = pd.read_csv(\"data/processed/train_sleep_add.csv\", parse_dates=['sleep_bedtime_start', 'sleep_bedtime_end'])\n",
    "test_activity = pd.read_csv(\"data/processed/test_activity_add.csv\", parse_dates=['activity_date'])\n",
    "test_sleep = pd.read_csv(\"data/processed/test_sleep_add.csv\", parse_dates=['sleep_bedtime_start', 'sleep_bedtime_end'])\n",
    "\n",
    "sleep_train_add = pd.read_csv(\"data/processed/sleep_train_add.csv\")\n",
    "sleep_test_add = pd.read_csv(\"data/processed/sleep_test_add.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Activity:  (9704, 60)\n",
      "Train Sleep:  (9705, 44)\n",
      "==============================\n",
      "Test Activity:  (2478, 60)\n",
      "Test Sleep:  (2478, 44)\n",
      "=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s\n",
      "Train Sleep:  (9705, 22)\n",
      "Test Sleep:  (2478, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Activity: \", train_activity.shape)\n",
    "print(\"Train Sleep: \", train_sleep.shape)\n",
    "print(\"=\"*30)\n",
    "print(\"Test Activity: \", test_activity.shape)\n",
    "print(\"Test Sleep: \", test_sleep.shape)\n",
    "print(\"=s\"*30)\n",
    "print(\"Train Sleep: \", sleep_train_add.shape)\n",
    "print(\"Test Sleep: \", sleep_test_add.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sleep['activity_date'] = train_sleep['sleep_bedtime_start'].dt.tz_localize(None).dt.normalize()\n",
    "idx = train_sleep[(train_sleep['EMAIL']=='nia+411@rowan.kr')&(train_sleep['activity_date']=='2020-12-05')].index\n",
    "train_sleep = train_sleep.drop(idx, axis=0).reset_index(drop=True)\n",
    "sleep_train_add = sleep_train_add.drop(idx, axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Activity:  (9704, 60)\n",
      "Train Sleep:  (9704, 45)\n",
      "==============================\n",
      "Test Activity:  (2478, 60)\n",
      "Test Sleep:  (2478, 44)\n",
      "=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s=s\n",
      "Train Sleep:  (9704, 22)\n",
      "Test Sleep:  (2478, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Activity: \", train_activity.shape)\n",
    "print(\"Train Sleep: \", train_sleep.shape)\n",
    "print(\"=\"*30)\n",
    "print(\"Test Activity: \", test_activity.shape)\n",
    "print(\"Test Sleep: \", test_sleep.shape)\n",
    "print(\"=s\"*30)\n",
    "print(\"Train Sleep: \", sleep_train_add.shape)\n",
    "print(\"Test Sleep: \", sleep_test_add.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_sleep_cols=['sleep_bedtime_start', 'sleep_bedtime_end', 'sleep_period_id',\n",
    "       'sleep_duration', 'sleep_total', 'sleep_awake', 'sleep_rem',\n",
    "       'sleep_light', 'sleep_deep', 'sleep_efficiency',\n",
    "       'sleep_midpoint_at_delta', 'sleep_midpoint_time', 'sleep_onset_latency',\n",
    "       'sleep_is_longest', 'sleep_breath_average', 'sleep_hr_average',\n",
    "       'sleep_hr_lowest', 'sleep_restless', 'sleep_rmssd', 'sleep_score',\n",
    "       'sleep_score_alignment', 'sleep_score_deep', 'sleep_score_disturbances',\n",
    "       'sleep_score_efficiency', 'sleep_score_latency', 'sleep_score_rem',\n",
    "       'sleep_score_total', 'sleep_temperature_delta',\n",
    "       'sleep_temperature_deviation', 'chronotype',\n",
    "       'wakeup_time_score', 'sleep_alignment_chronotype',\n",
    "       'sleep_alignment_chronotype_mins', 'sleep_duration_hours', 'wake_time',\n",
    "       'bed_time', 'avg_wake_time', 'avg_sleep_duration', 'std_wake_time',\n",
    "       'std_sleep_duration', 'sleep_alignment', 'abnormal_wake_time','DIAG_NM']\n",
    "sleep_train_add_cols=['sleep_consistency', 'sleep_consistency_30d_avg',\n",
    "       'sleep_startpoint_at_delta_norm', 'sleep_midpoint_at_delta_norm',\n",
    "       'sleep_end_hour', 'sleep_end_weekday', 'sleep_deep_ratio',\n",
    "       'sleep_light_ratio_3d_avg', 'deep_ratio_5h', 'deep_ratio_5h_lag2',\n",
    "       'deep_ratio_5h_3d_avg', 'deep_ratio_5h_30d_avg', 'awake_ratio_5h',\n",
    "       'awake_ratio_5h_3d_avg', 'awake_longest_duration_lag2',\n",
    "       'sleep_hr_lowest_lag2', 'hr_pattern_0', 'hr_pattern_3', 'hr_pattern_5',\n",
    "       'time_to_reach_mean_min']\n",
    "train_activity_cols=['EMAIL', 'activity_date', 'activity_non_wear', 'activity_total',\n",
    "       'activity_cal_active', 'activity_cal_total', 'activity_daily_movement',\n",
    "       'activity_steps', 'activity_inactivity_alerts', 'activity_rest',\n",
    "       'activity_inactive', 'activity_low', 'activity_medium', 'activity_high',\n",
    "       'activity_met_min_inactive', 'activity_met_min_low',\n",
    "       'activity_met_min_medium', 'activity_met_min_high',\n",
    "       'activity_average_met', 'activity_score',\n",
    "       'activity_score_meet_daily_targets', 'activity_score_move_every_hour',\n",
    "       'activity_score_recovery_time', 'activity_score_stay_active',\n",
    "       'activity_score_training_frequency', 'activity_score_training_volume',\n",
    "       'daytime', 'evening', 'morning', 'night', 'total_met',\n",
    "       'morning_ratio', 'evening_ratio', 'activity_type',\n",
    "       'activity_average_met_lag2', 'activity_average_met_lag3',\n",
    "       'activity_average_met_3d_avg', 'activity_average_met_7d_avg',\n",
    "       'activity_average_met_30d_avg', 'activity_inactive_lag2',\n",
    "       'activity_inactive_lag3', 'activity_inactive_3d_avg',\n",
    "       'activity_inactive_7d_avg', 'activity_inactive_30d_avg',\n",
    "       'total_met_lag2', 'total_met_lag3', 'total_met_3d_avg',\n",
    "       'total_met_7d_avg', 'total_met_30d_avg', 'morning_ratio_lag2',\n",
    "       'morning_ratio_lag3', 'morning_ratio_3d_avg', 'morning_ratio_7d_avg',\n",
    "       'morning_ratio_30d_avg', 'evening_ratio_lag2', 'evening_ratio_lag3',\n",
    "       'evening_ratio_3d_avg', 'evening_ratio_7d_avg',\n",
    "       'evening_ratio_30d_avg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = pd.concat([train_activity[train_activity_cols], sleep_train_add[sleep_train_add_cols], train_sleep[train_sleep_cols]], axis=1)\n",
    "test_final = pd.concat([test_activity[train_activity_cols], sleep_test_add[sleep_train_add_cols], test_sleep[train_sleep_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9704, 122)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2478, 122)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "folder=\"data/final\"\n",
    "os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "# train_label_merged.to_csv(log_folder+\"/train_label_merged.csv\", index=False)\n",
    "train_final.to_csv(folder+\"/train.csv\", index=False)\n",
    "test_final.to_csv(folder+\"/test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
