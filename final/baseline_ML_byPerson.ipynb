{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. raw data 모든 컬럼(int,float형 데이터) 사용 (이상치 제거X)\n",
    "2. 라벨 인코딩\n",
    "3. cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Seed 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2  # 1MB = 1024**2 Byte\n",
    "    for col in df.columns:\n",
    "        dtype_name = df[col].dtype.name\n",
    "        if dtype_name == \"object\":\n",
    "            pass\n",
    "        elif dtype_name == \"bool\":\n",
    "            df[col] = df[col].astype(\"int8\")\n",
    "        elif dtype_name.startswith(\"int\") or (df[col].round() == df[col]).all():\n",
    "            df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(\"{:.1f}% 압축됨\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- csv 파일명을 수정해야함 (training_activity -> train_activity, val_activity -> validation_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_path: str, dataset_type: str):\n",
    "    \"\"\" 데이터를 불러오는 함수 \"\"\"\n",
    "    label_path = f\"{base_path}/{dataset_type}/label/\"\n",
    "    raw_path = f\"{base_path}/{dataset_type}/raw/\"\n",
    "    \n",
    "    label = pd.read_csv(f\"{label_path}1.걸음걸이/{dataset_type}_label.csv\")\n",
    "    activity = pd.read_csv(f\"{raw_path}{dataset_type}_activity.csv\")\n",
    "    sleep = pd.read_csv(f\"{raw_path}{dataset_type}_sleep.csv\")\n",
    "    \n",
    "    return label, activity, sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"../data\"\n",
    "train_label, train_activity, train_sleep = load_data(BASE_PATH, \"train\")\n",
    "test_label, test_activity, test_sleep = load_data(BASE_PATH, \"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_drop_features(df):\n",
    "    \"\"\" 데이터 전처리 및 불필요한 피처 제거 \"\"\"\n",
    "    # 전처리 후 이메일\n",
    "    emails = df[\"EMAIL\"]\n",
    "    result_df = df.select_dtypes(include=[np.number])\n",
    "    result_df = result_df[result_df.columns.difference(['DIAG_NM'])]\n",
    "    \n",
    "    print(f\"전처리 후 피처 수: {len(result_df.columns)}\")\n",
    "    print(f\"전처리 후 사용되는 피처: {result_df.columns}\")\n",
    "    \n",
    "    return result_df, emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_process_data(activity_df, sleep_df, label_df):\n",
    "    \"\"\" 이메일 기준으로 데이터 병합 및 레이블 생성 \"\"\"\n",
    "    df = pd.concat([activity_df, sleep_df.drop(columns=['EMAIL'], errors='ignore')], axis=1)\n",
    "    label_df = label_df.rename(columns={\"SAMPLE_EMAIL\": \"EMAIL\"})\n",
    "    df = df.merge(label_df, how='inner', on='EMAIL')\n",
    "    df = downcast(df)\n",
    "    \n",
    "    X, emails = preprocess_and_drop_features(df)\n",
    "    y = df.iloc[:,-1]\n",
    "    \n",
    "    print(f'X shape: {X.shape}, y shape: {y.shape}')\n",
    "    \n",
    "    return X, y, emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.7% 압축됨\n",
      "전처리 후 피처 수: 51\n",
      "전처리 후 사용되는 피처: Index(['activity_average_met', 'activity_cal_active', 'activity_cal_total',\n",
      "       'activity_daily_movement', 'activity_high', 'activity_inactive',\n",
      "       'activity_inactivity_alerts', 'activity_low', 'activity_medium',\n",
      "       'activity_met_min_high', 'activity_met_min_inactive',\n",
      "       'activity_met_min_low', 'activity_met_min_medium', 'activity_non_wear',\n",
      "       'activity_rest', 'activity_score', 'activity_score_meet_daily_targets',\n",
      "       'activity_score_move_every_hour', 'activity_score_recovery_time',\n",
      "       'activity_score_stay_active', 'activity_score_training_frequency',\n",
      "       'activity_score_training_volume', 'activity_steps', 'activity_total',\n",
      "       'sleep_awake', 'sleep_breath_average', 'sleep_deep', 'sleep_duration',\n",
      "       'sleep_efficiency', 'sleep_hr_average', 'sleep_hr_lowest',\n",
      "       'sleep_is_longest', 'sleep_light', 'sleep_midpoint_at_delta',\n",
      "       'sleep_midpoint_time', 'sleep_onset_latency', 'sleep_period_id',\n",
      "       'sleep_rem', 'sleep_restless', 'sleep_rmssd', 'sleep_score',\n",
      "       'sleep_score_alignment', 'sleep_score_deep', 'sleep_score_disturbances',\n",
      "       'sleep_score_efficiency', 'sleep_score_latency', 'sleep_score_rem',\n",
      "       'sleep_score_total', 'sleep_temperature_delta',\n",
      "       'sleep_temperature_deviation', 'sleep_total'],\n",
      "      dtype='object')\n",
      "X shape: (9705, 51), y shape: (9705,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, train_emails = merge_and_process_data(train_activity, train_sleep, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가\n",
    "models = {\n",
    "    \"Lasso Regression\": LogisticRegression(penalty='l1', solver='liblinear', multi_class='ovr'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_SEED),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear', probability=True, random_state=RANDOM_SEED),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_SEED),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_SEED, n_jobs=-1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습 및 성능 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(X):    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)  # 표준화를 적용\n",
    "    return scaler, X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, X_train_scaled = scale_features(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(y):\n",
    "    \"\"\" 클래스 레이블을 숫자로 변환 \"\"\"\n",
    "    label_encoder = {\"CN\": 0, \"MCI\": 1, \"Dem\": 2}\n",
    "    return y.map(label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = encode_label(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedGroupKFold 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 3\n",
    "sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# train/val 인덱스 저장\n",
    "sgkf_splits = []\n",
    "for train_idx, val_idx in sgkf.split(X_train_scaled, y_train_encoded, train_emails):\n",
    "    sgkf_splits.append((train_idx, val_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 일별 성능 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_daily_performance(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    일별 성능 평가\n",
    "    \n",
    "    Args:\n",
    "        y_true (pd.Series): 실제 레이블\n",
    "        y_pred (np.ndarray): 예측 레이블\n",
    "    \n",
    "    Returns:\n",
    "        dict: Accuracy, F1-score, 그리고 Classification Report 데이터프레임\n",
    "    \"\"\"\n",
    "    daily_acc = accuracy_score(y_true, y_pred)\n",
    "    daily_f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "    \n",
    "    # Classification Report 생성\n",
    "    report_daily = classification_report(y_true, y_pred, output_dict=True)\n",
    "    report_daily_df = pd.DataFrame(report_daily).T\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": daily_acc,\n",
    "        \"f1_score\": daily_f1,\n",
    "        \"classification_report\": report_daily_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사람별 성능 평가 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_person_performance(val_emails, y_true, y_pred):\n",
    "    \"\"\"\n",
    "    사람별 성능 평가 (EMAIL 단위 그룹화)\n",
    "    \n",
    "    Args:\n",
    "        val_emails (pd.Series): EMAIL 정보\n",
    "        y_true (pd.Series): 실제 레이블\n",
    "        y_pred (np.ndarray): 예측 레이블\n",
    "    \n",
    "    Returns:\n",
    "        dict: Accuracy, F1-score, 그리고 Classification Report 데이터프레임\n",
    "    \"\"\"\n",
    "    val_data = pd.DataFrame({\"EMAIL\": val_emails, \"label\": y_true, \"pred\": y_pred})\n",
    "    grouped = val_data.groupby(\"EMAIL\")\n",
    "\n",
    "    email_true_labels = []\n",
    "    email_pred_labels = []\n",
    "\n",
    "    for email, group in grouped:\n",
    "        # 실제 레이블: 해당 EMAIL의 모든 레이블 중 첫 번째 값 (모든 데이터가 동일하다고 가정)\n",
    "        true_label = group[\"label\"].iloc[0]\n",
    "        email_true_labels.append(true_label)\n",
    "\n",
    "        # 예측 레이블: 해당 EMAIL의 예측값 중 최빈값 (빈도 동일 시 큰 값 선택)\n",
    "        pred_counter = Counter(group[\"pred\"])\n",
    "        most_common = pred_counter.most_common()  # [(label1, count1), (label2, count2), ...]\n",
    "        max_count = most_common[0][1]  # 최빈값의 빈도수\n",
    "        candidates = [label for label, count in most_common if count == max_count]  # 빈도가 같은 후보들\n",
    "        most_common_label = max(candidates)  # 빈도가 동일한 경우 가장 큰 값 선택\n",
    "        email_pred_labels.append(most_common_label)\n",
    "\n",
    "    person_acc = accuracy_score(email_true_labels, email_pred_labels)\n",
    "    person_f1 = f1_score(email_true_labels, email_pred_labels, average=\"weighted\")\n",
    "    \n",
    "    # Classification Report 생성\n",
    "    report_person = classification_report(email_true_labels, email_pred_labels, output_dict=True)\n",
    "    report_person_df = pd.DataFrame(report_person).T\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": person_acc,\n",
    "        \"f1_score\": person_f1,\n",
    "        \"classification_report\": report_person_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model: Lasso Regression ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Average Daily Accuracy: 0.54\n",
      "Average Daily F1-score: 0.50\n",
      "=== Average Daily Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.60    0.77      0.67  1927.00\n",
      "1                  0.35    0.22      0.27  1117.67\n",
      "2                  0.21    0.06      0.09   190.33\n",
      "accuracy           0.54    0.54      0.54     0.54\n",
      "macro avg          0.39    0.35      0.35  3235.00\n",
      "weighted avg       0.50    0.54      0.50  3235.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Average Person-Level Accuracy: 0.57\n",
      "Average Person-Level F1-score: 0.51\n",
      "=== Average Person-Level Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.61    0.86      0.71    28.33\n",
      "1                  0.35    0.17      0.23    15.67\n",
      "2                  0.00    0.00      0.00     3.00\n",
      "accuracy           0.57    0.57      0.57     0.57\n",
      "macro avg          0.32    0.34      0.32    47.00\n",
      "weighted avg       0.49    0.57      0.51    47.00\n",
      "============================================================\n",
      "### Model: Decision Tree ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Average Daily Accuracy: 0.49\n",
      "Average Daily F1-score: 0.49\n",
      "=== Average Daily Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.61    0.60      0.60  1927.00\n",
      "1                  0.36    0.37      0.36  1117.67\n",
      "2                  0.14    0.12      0.12   190.33\n",
      "accuracy           0.49    0.49      0.49     0.49\n",
      "macro avg          0.37    0.37      0.36  3235.00\n",
      "weighted avg       0.50    0.49      0.49  3235.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Average Person-Level Accuracy: 0.53\n",
      "Average Person-Level F1-score: 0.49\n",
      "=== Average Person-Level Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.60    0.77      0.67    28.33\n",
      "1                  0.33    0.22      0.25    15.67\n",
      "2                  0.00    0.00      0.00     3.00\n",
      "accuracy           0.53    0.53      0.53     0.53\n",
      "macro avg          0.31    0.33      0.31    47.00\n",
      "weighted avg       0.48    0.53      0.49    47.00\n",
      "============================================================\n",
      "### Model: Support Vector Machine ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Average Daily Accuracy: 0.54\n",
      "Average Daily F1-score: 0.49\n",
      "=== Average Daily Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.60    0.80      0.68  1927.00\n",
      "1                  0.34    0.17      0.22  1117.67\n",
      "2                  0.18    0.04      0.07   190.33\n",
      "accuracy           0.54    0.54      0.54     0.54\n",
      "macro avg          0.37    0.34      0.33  3235.00\n",
      "weighted avg       0.49    0.54      0.49  3235.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Average Person-Level Accuracy: 0.57\n",
      "Average Person-Level F1-score: 0.48\n",
      "=== Average Person-Level Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.60    0.91      0.72    28.33\n",
      "1                  0.24    0.08      0.12    15.67\n",
      "2                  0.00    0.00      0.00     3.00\n",
      "accuracy           0.57    0.57      0.57     0.57\n",
      "macro avg          0.28    0.33      0.28    47.00\n",
      "weighted avg       0.45    0.57      0.48    47.00\n",
      "============================================================\n",
      "### Model: Gradient Boosting ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Average Daily Accuracy: 0.55\n",
      "Average Daily F1-score: 0.52\n",
      "=== Average Daily Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.61    0.76      0.68  1927.00\n",
      "1                  0.39    0.27      0.32  1117.67\n",
      "2                  0.24    0.08      0.11   190.33\n",
      "accuracy           0.55    0.55      0.55     0.55\n",
      "macro avg          0.41    0.37      0.37  3235.00\n",
      "weighted avg       0.52    0.55      0.52  3235.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Average Person-Level Accuracy: 0.60\n",
      "Average Person-Level F1-score: 0.53\n",
      "=== Average Person-Level Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.62    0.87      0.73    28.33\n",
      "1                  0.51    0.22      0.29    15.67\n",
      "2                  0.00    0.00      0.00     3.00\n",
      "accuracy           0.60    0.60      0.60     0.60\n",
      "macro avg          0.38    0.36      0.34    47.00\n",
      "weighted avg       0.55    0.60      0.53    47.00\n",
      "============================================================\n",
      "### Model: Random Forest ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Average Daily Accuracy: 0.56\n",
      "Average Daily F1-score: 0.51\n",
      "=== Average Daily Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.60    0.82      0.69  1927.00\n",
      "1                  0.39    0.21      0.27  1117.67\n",
      "2                  0.27    0.03      0.05   190.33\n",
      "accuracy           0.56    0.56      0.56     0.56\n",
      "macro avg          0.42    0.35      0.34  3235.00\n",
      "weighted avg       0.52    0.56      0.51  3235.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Average Person-Level Accuracy: 0.61\n",
      "Average Person-Level F1-score: 0.53\n",
      "=== Average Person-Level Classification Report ===\n",
      "              precision  recall  f1-score  support\n",
      "0                  0.62    0.93      0.74    28.33\n",
      "1                  0.59    0.15      0.24    15.67\n",
      "2                  0.00    0.00      0.00     3.00\n",
      "accuracy           0.61    0.61      0.61     0.61\n",
      "macro avg          0.40    0.36      0.33    47.00\n",
      "weighted avg       0.57    0.61      0.53    47.00\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "final_models = {} # 최종 모델 저장\n",
    "\n",
    "for name, model in models.items():\n",
    "    \n",
    "    daily_acc_scores = []  # 일별 Accuracy 저장\n",
    "    daily_f1_scores = []   # 일별 F1-score 저장\n",
    "    person_acc_scores = []  # 사람별 Accuracy 저장\n",
    "    person_f1_scores = []   # 사람별 F1-score 저장\n",
    "    class_report_list_daily = []  # 일별 Classification Report 저장\n",
    "    class_report_list_person = []  # 사람별 Classification Report 저장\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(sgkf_splits):\n",
    "        X_train_fold, X_val_fold = X_train_scaled[train_idx], X_train_scaled[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_encoded.iloc[train_idx], y_train_encoded.iloc[val_idx]\n",
    "        val_emails = train_emails.iloc[val_idx]  # Validation 데이터의 EMAIL 컬럼\n",
    "\n",
    "        # 모델 학습 및 예측\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        # === 일별 성능 평가 ===\n",
    "        daily_result = evaluate_daily_performance(y_val_fold, y_pred)\n",
    "        daily_acc_scores.append(daily_result[\"accuracy\"])\n",
    "        daily_f1_scores.append(daily_result[\"f1_score\"])\n",
    "        class_report_list_daily.append(daily_result[\"classification_report\"])\n",
    "\n",
    "        # === 사람별 성능 평가 ===\n",
    "        person_result = evaluate_person_performance(val_emails, y_val_fold, y_pred)\n",
    "        person_acc_scores.append(person_result[\"accuracy\"])\n",
    "        person_f1_scores.append(person_result[\"f1_score\"])\n",
    "        class_report_list_person.append(person_result[\"classification_report\"])\n",
    "\n",
    "    # === 평균 계산 및 결과 출력 ===\n",
    "\n",
    "    # 일별 평균 Classification Report 계산\n",
    "    avg_class_report_daily = pd.concat(class_report_list_daily).groupby(level=0).mean()\n",
    "\n",
    "    # 사람별 평균 Classification Report 계산\n",
    "    avg_class_report_person = pd.concat(class_report_list_person).groupby(level=0).mean()\n",
    "\n",
    "    print(\"###\", f\"Model: {name}\", \"###\")\n",
    "\n",
    "    print(\"\\n=== Daily Performance ===\")\n",
    "    print(f\"Average Daily Accuracy: {np.mean(daily_acc_scores):.2f}\")\n",
    "    print(f\"Average Daily F1-score: {np.mean(daily_f1_scores):.2f}\")\n",
    "    print(\"=== Average Daily Classification Report ===\")\n",
    "    print(avg_class_report_daily.round(2))\n",
    "\n",
    "    print(\"\\n=== Person-Level Performance ===\")\n",
    "    print(f\"Average Person-Level Accuracy: {np.mean(person_acc_scores):.2f}\")\n",
    "    print(f\"Average Person-Level F1-score: {np.mean(person_f1_scores):.2f}\")\n",
    "    print(\"=== Average Person-Level Classification Report ===\")\n",
    "    print(avg_class_report_person.round(2))\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    final_models[name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv 는 학습에 안 쓰이는 폴드가 있으므로 전체 데이터로 학습을 다시 진행\n",
    "def learn_model(name, model, X, y):\n",
    "    model.fit(X, y)\n",
    "    return name, model\n",
    "\n",
    "for name, model in models.items():\n",
    "    name_, model_ = learn_model(name, model, X_train_scaled, y_train_encoded)\n",
    "    final_models[name] = model_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset 예측 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.8% 압축됨\n",
      "전처리 후 피처 수: 51\n",
      "전처리 후 사용되는 피처: Index(['activity_average_met', 'activity_cal_active', 'activity_cal_total',\n",
      "       'activity_daily_movement', 'activity_high', 'activity_inactive',\n",
      "       'activity_inactivity_alerts', 'activity_low', 'activity_medium',\n",
      "       'activity_met_min_high', 'activity_met_min_inactive',\n",
      "       'activity_met_min_low', 'activity_met_min_medium', 'activity_non_wear',\n",
      "       'activity_rest', 'activity_score', 'activity_score_meet_daily_targets',\n",
      "       'activity_score_move_every_hour', 'activity_score_recovery_time',\n",
      "       'activity_score_stay_active', 'activity_score_training_frequency',\n",
      "       'activity_score_training_volume', 'activity_steps', 'activity_total',\n",
      "       'sleep_awake', 'sleep_breath_average', 'sleep_deep', 'sleep_duration',\n",
      "       'sleep_efficiency', 'sleep_hr_average', 'sleep_hr_lowest',\n",
      "       'sleep_is_longest', 'sleep_light', 'sleep_midpoint_at_delta',\n",
      "       'sleep_midpoint_time', 'sleep_onset_latency', 'sleep_period_id',\n",
      "       'sleep_rem', 'sleep_restless', 'sleep_rmssd', 'sleep_score',\n",
      "       'sleep_score_alignment', 'sleep_score_deep', 'sleep_score_disturbances',\n",
      "       'sleep_score_efficiency', 'sleep_score_latency', 'sleep_score_rem',\n",
      "       'sleep_score_total', 'sleep_temperature_delta',\n",
      "       'sleep_temperature_deviation', 'sleep_total'],\n",
      "      dtype='object')\n",
      "X shape: (2478, 51), y shape: (2478,)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test, test_emails = merge_and_process_data(test_activity, test_sleep, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data, Test data Exclusivity 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_emails) & set(test_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_test_encoded = encode_label(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model: Lasso Regression ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Test Accuracy (by Day): 0.67\n",
      "Test F1-score (by Day): 0.67\n",
      "Test Classification Report (by Day):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.79    0.81      0.80  1956.00\n",
      "1                  0.08    0.11      0.10   308.00\n",
      "2                  0.85    0.23      0.37   214.00\n",
      "accuracy           0.67    0.67      0.67     0.67\n",
      "macro avg          0.57    0.38      0.42  2478.00\n",
      "weighted avg       0.70    0.67      0.67  2478.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Test Accuracy (by EMAIL): 0.73\n",
      "Test F1-score (by EMAIL): 0.70\n",
      "Test Classification Report (by EMAIL):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.79    0.88      0.84    26.00\n",
      "1                  0.00    0.00      0.00     4.00\n",
      "2                  1.00    0.33      0.50     3.00\n",
      "accuracy           0.73    0.73      0.73     0.73\n",
      "macro avg          0.60    0.41      0.45    33.00\n",
      "weighted avg       0.72    0.73      0.70    33.00\n",
      "============================================================\n",
      "### Model: Decision Tree ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Test Accuracy (by Day): 0.54\n",
      "Test F1-score (by Day): 0.59\n",
      "Test Classification Report (by Day):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.80    0.60      0.68  1956.00\n",
      "1                  0.12    0.35      0.18   308.00\n",
      "2                  0.43    0.30      0.36   214.00\n",
      "accuracy           0.54    0.54      0.54     0.54\n",
      "macro avg          0.45    0.42      0.41  2478.00\n",
      "weighted avg       0.68    0.54      0.59  2478.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Test Accuracy (by EMAIL): 0.70\n",
      "Test F1-score (by EMAIL): 0.71\n",
      "Test Classification Report (by EMAIL):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.81    0.81      0.81     26.0\n",
      "1                  0.00    0.00      0.00      4.0\n",
      "2                  1.00    0.67      0.80      3.0\n",
      "accuracy           0.70    0.70      0.70      0.7\n",
      "macro avg          0.60    0.49      0.54     33.0\n",
      "weighted avg       0.73    0.70      0.71     33.0\n",
      "============================================================\n",
      "### Model: Support Vector Machine ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Test Accuracy (by Day): 0.76\n",
      "Test F1-score (by Day): 0.72\n",
      "Test Classification Report (by Day):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.80    0.94      0.86  1956.00\n",
      "1                  0.06    0.02      0.03   308.00\n",
      "2                  0.92    0.21      0.34   214.00\n",
      "accuracy           0.76    0.76      0.76     0.76\n",
      "macro avg          0.59    0.39      0.41  2478.00\n",
      "weighted avg       0.72    0.76      0.72  2478.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Test Accuracy (by EMAIL): 0.82\n",
      "Test F1-score (by EMAIL): 0.75\n",
      "Test Classification Report (by EMAIL):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.81    1.00      0.90    26.00\n",
      "1                  0.00    0.00      0.00     4.00\n",
      "2                  1.00    0.33      0.50     3.00\n",
      "accuracy           0.82    0.82      0.82     0.82\n",
      "macro avg          0.60    0.44      0.47    33.00\n",
      "weighted avg       0.73    0.82      0.75    33.00\n",
      "============================================================\n",
      "### Model: Gradient Boosting ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Test Accuracy (by Day): 0.63\n",
      "Test F1-score (by Day): 0.64\n",
      "Test Classification Report (by Day):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.77    0.77      0.77  1956.00\n",
      "1                  0.04    0.07      0.05   308.00\n",
      "2                  0.88    0.17      0.29   214.00\n",
      "accuracy           0.63    0.63      0.63     0.63\n",
      "macro avg          0.57    0.34      0.37  2478.00\n",
      "weighted avg       0.69    0.63      0.64  2478.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Test Accuracy (by EMAIL): 0.67\n",
      "Test F1-score (by EMAIL): 0.67\n",
      "Test Classification Report (by EMAIL):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.78    0.81      0.79    26.00\n",
      "1                  0.00    0.00      0.00     4.00\n",
      "2                  1.00    0.33      0.50     3.00\n",
      "accuracy           0.67    0.67      0.67     0.67\n",
      "macro avg          0.59    0.38      0.43    33.00\n",
      "weighted avg       0.70    0.67      0.67    33.00\n",
      "============================================================\n",
      "### Model: Random Forest ###\n",
      "\n",
      "=== Daily Performance ===\n",
      "Test Accuracy (by Day): 0.67\n",
      "Test F1-score (by Day): 0.66\n",
      "Test Classification Report (by Day):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.78    0.81      0.80  1956.00\n",
      "1                  0.05    0.06      0.06   308.00\n",
      "2                  0.93    0.18      0.30   214.00\n",
      "accuracy           0.67    0.67      0.67     0.67\n",
      "macro avg          0.59    0.35      0.39  2478.00\n",
      "weighted avg       0.70    0.67      0.66  2478.00\n",
      "\n",
      "=== Person-Level Performance ===\n",
      "Test Accuracy (by EMAIL): 0.73\n",
      "Test F1-score (by EMAIL): 0.70\n",
      "Test Classification Report (by EMAIL):\n",
      "               precision  recall  f1-score  support\n",
      "0                  0.79    0.88      0.84    26.00\n",
      "1                  0.00    0.00      0.00     4.00\n",
      "2                  1.00    0.33      0.50     3.00\n",
      "accuracy           0.73    0.73      0.73     0.73\n",
      "macro avg          0.60    0.41      0.45    33.00\n",
      "weighted avg       0.72    0.73      0.70    33.00\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for name, model in final_models.items():\n",
    "    print(\"###\", f\"Model: {name}\", \"###\")\n",
    "    \n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # === 일별 성능 평가 ===\n",
    "    daily_result = evaluate_daily_performance(y_test_encoded, y_test_pred)\n",
    "\n",
    "    # 일별 성능 지표 추출\n",
    "    daily_acc = daily_result[\"accuracy\"]\n",
    "    daily_f1 = daily_result[\"f1_score\"]\n",
    "    daily_report = daily_result[\"classification_report\"]\n",
    "\n",
    "    # === 사람별 성능 평가 ===\n",
    "    person_result = evaluate_person_performance(test_emails, y_test_encoded, y_test_pred)\n",
    "\n",
    "    # 사람별 성능 지표 추출\n",
    "    person_acc = person_result[\"accuracy\"]\n",
    "    person_f1 = person_result[\"f1_score\"]\n",
    "    person_report = person_result[\"classification_report\"]\n",
    "\n",
    "    # 결과 출력\n",
    "    print(\"\\n=== Daily Performance ===\")\n",
    "    print(f\"Test Accuracy (by Day): {daily_acc:.2f}\")\n",
    "    print(f\"Test F1-score (by Day): {daily_f1:.2f}\")\n",
    "    print(\"Test Classification Report (by Day):\\n\", daily_report.round(2))\n",
    "\n",
    "    print(\"\\n=== Person-Level Performance ===\")\n",
    "    print(f\"Test Accuracy (by EMAIL): {person_acc:.2f}\")\n",
    "    print(f\"Test F1-score (by EMAIL): {person_f1:.2f}\")\n",
    "    print(\"Test Classification Report (by EMAIL):\\n\", person_report.round(2))\n",
    "    \n",
    "    print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env2501",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
